{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('C:/Users/RVALENZUELA/Desktop/RVC 2020/RENE/X/MK Digital/LETS UP GRADE/Datasets/User_Data - Arindam Dev (1).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, [0,3]].values\n",
    "y = dataset.iloc[:,4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User ID  Gender  Age  EstimatedSalary  Purchased\n",
       "0  15624510    Male   19            19000          0\n",
       "1  15810944    Male   35            20000          0\n",
       "2  15668575  Female   26            43000          0\n",
       "3  15603246  Female   27            57000          0\n",
       "4  15804002    Male   19            76000          0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25,random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy')\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[58, 10],\n",
       "       [13, 19]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.77\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: ',accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Classification Reports is as follows...\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.83        68\n",
      "           1       0.66      0.59      0.62        32\n",
      "\n",
      "    accuracy                           0.77       100\n",
      "   macro avg       0.74      0.72      0.73       100\n",
      "weighted avg       0.77      0.77      0.77       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print('The Classification Reports is as follows...\\n')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real Values</th>\n",
       "      <th>Predicted Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Real Values  Predicted Values\n",
       "0             0                 0\n",
       "1             0                 0\n",
       "2             0                 0\n",
       "3             0                 0\n",
       "4             0                 0\n",
       "..          ...               ...\n",
       "95            1                 1\n",
       "96            0                 0\n",
       "97            1                 1\n",
       "98            1                 1\n",
       "99            1                 1\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Real Values':y_test.reshape(-1), 'Predicted Values':y_pred.reshape(-1)})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[53, 15],\n",
       "       [13, 19]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.72\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy Score: ',accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Classification Report is as follows...\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79        68\n",
      "           1       0.56      0.59      0.58        32\n",
      "\n",
      "    accuracy                           0.72       100\n",
      "   macro avg       0.68      0.69      0.68       100\n",
      "weighted avg       0.72      0.72      0.72       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print('The Classification Report is as follows...\\n')\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real Values</th>\n",
       "      <th>Predicted Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Real Values  Predicted Values\n",
       "0             0                 0\n",
       "1             0                 0\n",
       "2             0                 0\n",
       "3             0                 0\n",
       "4             0                 0\n",
       "..          ...               ...\n",
       "95            1                 1\n",
       "96            0                 0\n",
       "97            1                 1\n",
       "98            1                 1\n",
       "99            1                 1\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.DataFrame({'Real Values': y_test.reshape(-1), 'Predicted Values': y_pred.reshape(-1)})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(214.83, 212.26285714285714, 'X[1] <= 0.606\\nentropy = 0.951\\nsamples = 300\\nvalue = [189, 111]'),\n",
       " Text(146.94, 201.90857142857143, 'X[1] <= -0.814\\nentropy = 0.787\\nsamples = 234\\nvalue = [179, 55]'),\n",
       " Text(74.4, 191.5542857142857, 'X[1] <= -1.452\\nentropy = 0.982\\nsamples = 69\\nvalue = [40, 29]'),\n",
       " Text(66.96000000000001, 181.2, 'entropy = 0.0\\nsamples = 13\\nvalue = [13, 0]'),\n",
       " Text(81.84, 181.2, 'X[0] <= -0.29\\nentropy = 0.999\\nsamples = 56\\nvalue = [27, 29]'),\n",
       " Text(52.080000000000005, 170.84571428571428, 'X[0] <= -1.252\\nentropy = 0.845\\nsamples = 22\\nvalue = [6, 16]'),\n",
       " Text(37.2, 160.49142857142857, 'X[1] <= -1.206\\nentropy = 0.863\\nsamples = 7\\nvalue = [5, 2]'),\n",
       " Text(29.76, 150.13714285714286, 'X[0] <= -1.334\\nentropy = 0.971\\nsamples = 5\\nvalue = [3, 2]'),\n",
       " Text(22.32, 139.78285714285715, 'X[0] <= -1.385\\nentropy = 0.811\\nsamples = 4\\nvalue = [3, 1]'),\n",
       " Text(14.88, 129.42857142857144, 'X[0] <= -1.459\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(7.44, 119.07428571428571, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(22.32, 119.07428571428571, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(29.76, 129.42857142857144, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(37.2, 139.78285714285715, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(44.64, 150.13714285714286, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(66.96000000000001, 160.49142857142857, 'X[1] <= -0.901\\nentropy = 0.353\\nsamples = 15\\nvalue = [1, 14]'),\n",
       " Text(59.52, 150.13714285714286, 'entropy = 0.0\\nsamples = 13\\nvalue = [0, 13]'),\n",
       " Text(74.4, 150.13714285714286, 'X[0] <= -0.914\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(66.96000000000001, 139.78285714285715, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(81.84, 139.78285714285715, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(111.60000000000001, 170.84571428571428, 'X[1] <= -1.365\\nentropy = 0.96\\nsamples = 34\\nvalue = [21, 13]'),\n",
       " Text(104.16000000000001, 160.49142857142857, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(119.04, 160.49142857142857, 'X[1] <= -1.322\\nentropy = 0.974\\nsamples = 32\\nvalue = [19, 13]'),\n",
       " Text(104.16000000000001, 150.13714285714286, 'X[0] <= -0.047\\nentropy = 0.811\\nsamples = 4\\nvalue = [1, 3]'),\n",
       " Text(96.72, 139.78285714285715, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(111.60000000000001, 139.78285714285715, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(133.92000000000002, 150.13714285714286, 'X[0] <= -0.218\\nentropy = 0.94\\nsamples = 28\\nvalue = [18, 10]'),\n",
       " Text(126.48, 139.78285714285715, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(141.36, 139.78285714285715, 'X[1] <= -0.858\\nentropy = 0.918\\nsamples = 27\\nvalue = [18, 9]'),\n",
       " Text(133.92000000000002, 129.42857142857144, 'X[0] <= 1.585\\nentropy = 0.89\\nsamples = 26\\nvalue = [18, 8]'),\n",
       " Text(119.04, 119.07428571428571, 'X[1] <= -0.901\\nentropy = 0.828\\nsamples = 23\\nvalue = [17, 6]'),\n",
       " Text(111.60000000000001, 108.72, 'X[1] <= -1.177\\nentropy = 0.773\\nsamples = 22\\nvalue = [17, 5]'),\n",
       " Text(93.0, 98.36571428571429, 'X[0] <= 0.243\\nentropy = 0.946\\nsamples = 11\\nvalue = [7, 4]'),\n",
       " Text(78.12, 88.01142857142858, 'X[0] <= 0.144\\nentropy = 0.971\\nsamples = 5\\nvalue = [2, 3]'),\n",
       " Text(70.68, 77.65714285714284, 'X[1] <= -1.235\\nentropy = 0.918\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(63.24, 67.30285714285714, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(78.12, 67.30285714285714, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(85.56, 77.65714285714284, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(107.88000000000001, 88.01142857142858, 'X[0] <= 0.542\\nentropy = 0.65\\nsamples = 6\\nvalue = [5, 1]'),\n",
       " Text(100.44000000000001, 77.65714285714284, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(115.32000000000001, 77.65714285714284, 'X[0] <= 0.646\\nentropy = 0.918\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(107.88000000000001, 67.30285714285714, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(122.76, 67.30285714285714, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(130.20000000000002, 98.36571428571429, 'X[0] <= 0.946\\nentropy = 0.439\\nsamples = 11\\nvalue = [10, 1]'),\n",
       " Text(122.76, 88.01142857142858, 'entropy = 0.0\\nsamples = 8\\nvalue = [8, 0]'),\n",
       " Text(137.64000000000001, 88.01142857142858, 'X[1] <= -1.046\\nentropy = 0.918\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(130.20000000000002, 77.65714285714284, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(145.08, 77.65714285714284, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(126.48, 108.72, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(148.8, 119.07428571428571, 'X[1] <= -0.974\\nentropy = 0.918\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(141.36, 108.72, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(156.24, 108.72, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(148.8, 129.42857142857144, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(219.48000000000002, 191.5542857142857, 'X[1] <= 0.49\\nentropy = 0.628\\nsamples = 165\\nvalue = [139, 26]'),\n",
       " Text(193.44, 181.2, 'X[0] <= 1.231\\nentropy = 0.562\\nsamples = 152\\nvalue = [132, 20]'),\n",
       " Text(186.0, 170.84571428571428, 'X[0] <= -1.651\\nentropy = 0.611\\nsamples = 133\\nvalue = [113, 20]'),\n",
       " Text(171.12, 160.49142857142857, 'X[0] <= -1.659\\nentropy = 0.918\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(163.68, 150.13714285714286, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(178.56, 150.13714285714286, 'X[0] <= -1.656\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(171.12, 139.78285714285715, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(186.0, 139.78285714285715, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(200.88000000000002, 160.49142857142857, 'X[0] <= -1.38\\nentropy = 0.58\\nsamples = 130\\nvalue = [112, 18]'),\n",
       " Text(193.44, 150.13714285714286, 'entropy = 0.0\\nsamples = 15\\nvalue = [15, 0]'),\n",
       " Text(208.32000000000002, 150.13714285714286, 'X[0] <= -1.365\\nentropy = 0.626\\nsamples = 115\\nvalue = [97, 18]'),\n",
       " Text(200.88000000000002, 139.78285714285715, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(215.76000000000002, 139.78285714285715, 'X[0] <= -1.139\\nentropy = 0.608\\nsamples = 114\\nvalue = [97, 17]'),\n",
       " Text(208.32000000000002, 129.42857142857144, 'entropy = 0.0\\nsamples = 12\\nvalue = [12, 0]'),\n",
       " Text(223.20000000000002, 129.42857142857144, 'X[0] <= -1.126\\nentropy = 0.65\\nsamples = 102\\nvalue = [85, 17]'),\n",
       " Text(215.76000000000002, 119.07428571428571, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(230.64000000000001, 119.07428571428571, 'X[1] <= 0.288\\nentropy = 0.61\\nsamples = 100\\nvalue = [85, 15]'),\n",
       " Text(223.20000000000002, 108.72, 'X[1] <= 0.085\\nentropy = 0.663\\nsamples = 87\\nvalue = [72, 15]'),\n",
       " Text(189.72, 98.36571428571429, 'X[0] <= 0.632\\nentropy = 0.548\\nsamples = 71\\nvalue = [62, 9]'),\n",
       " Text(167.4, 88.01142857142858, 'X[0] <= -0.56\\nentropy = 0.318\\nsamples = 52\\nvalue = [49, 3]'),\n",
       " Text(159.96, 77.65714285714284, 'X[0] <= -0.892\\nentropy = 0.779\\nsamples = 13\\nvalue = [10, 3]'),\n",
       " Text(152.52, 67.30285714285714, 'entropy = 0.0\\nsamples = 6\\nvalue = [6, 0]'),\n",
       " Text(167.4, 67.30285714285714, 'X[0] <= -0.787\\nentropy = 0.985\\nsamples = 7\\nvalue = [4, 3]'),\n",
       " Text(159.96, 56.94857142857143, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(174.84, 56.94857142857143, 'X[0] <= -0.65\\nentropy = 0.722\\nsamples = 5\\nvalue = [4, 1]'),\n",
       " Text(167.4, 46.59428571428572, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(182.28, 46.59428571428572, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(174.84, 77.65714285714284, 'entropy = 0.0\\nsamples = 39\\nvalue = [39, 0]'),\n",
       " Text(212.04000000000002, 88.01142857142858, 'X[1] <= -0.727\\nentropy = 0.9\\nsamples = 19\\nvalue = [13, 6]'),\n",
       " Text(204.60000000000002, 77.65714285714284, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(219.48000000000002, 77.65714285714284, 'X[1] <= 0.027\\nentropy = 0.954\\nsamples = 16\\nvalue = [10, 6]'),\n",
       " Text(212.04000000000002, 67.30285714285714, 'X[1] <= -0.06\\nentropy = 0.996\\nsamples = 13\\nvalue = [7, 6]'),\n",
       " Text(204.60000000000002, 56.94857142857143, 'X[0] <= 0.815\\nentropy = 0.946\\nsamples = 11\\nvalue = [7, 4]'),\n",
       " Text(197.16, 46.59428571428572, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(212.04000000000002, 46.59428571428572, 'X[0] <= 1.067\\nentropy = 0.764\\nsamples = 9\\nvalue = [7, 2]'),\n",
       " Text(204.60000000000002, 36.24000000000001, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(219.48000000000002, 36.24000000000001, 'X[1] <= -0.51\\nentropy = 1.0\\nsamples = 4\\nvalue = [2, 2]'),\n",
       " Text(212.04000000000002, 25.8857142857143, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(226.92000000000002, 25.8857142857143, 'X[1] <= -0.365\\nentropy = 0.918\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(219.48000000000002, 15.531428571428563, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(234.36, 15.531428571428563, 'X[1] <= -0.205\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(226.92000000000002, 5.177142857142854, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(241.8, 5.177142857142854, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(219.48000000000002, 56.94857142857143, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(226.92000000000002, 67.30285714285714, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(256.68, 98.36571428571429, 'X[0] <= -0.757\\nentropy = 0.954\\nsamples = 16\\nvalue = [10, 6]'),\n",
       " Text(249.24, 88.01142857142858, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(264.12, 88.01142857142858, 'X[0] <= 0.643\\nentropy = 0.985\\nsamples = 14\\nvalue = [8, 6]'),\n",
       " Text(256.68, 77.65714285714284, 'X[1] <= 0.143\\nentropy = 1.0\\nsamples = 12\\nvalue = [6, 6]'),\n",
       " Text(241.8, 67.30285714285714, 'X[0] <= 0.021\\nentropy = 0.811\\nsamples = 4\\nvalue = [1, 3]'),\n",
       " Text(234.36, 56.94857142857143, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(249.24, 56.94857142857143, 'X[0] <= 0.368\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(241.8, 46.59428571428572, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(256.68, 46.59428571428572, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(271.56, 67.30285714285714, 'X[1] <= 0.172\\nentropy = 0.954\\nsamples = 8\\nvalue = [5, 3]'),\n",
       " Text(264.12, 56.94857142857143, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(279.0, 56.94857142857143, 'X[0] <= -0.618\\nentropy = 1.0\\nsamples = 6\\nvalue = [3, 3]'),\n",
       " Text(271.56, 46.59428571428572, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(286.44, 46.59428571428572, 'X[0] <= -0.137\\nentropy = 0.971\\nsamples = 5\\nvalue = [3, 2]'),\n",
       " Text(279.0, 36.24000000000001, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(293.88, 36.24000000000001, 'X[0] <= 0.028\\nentropy = 0.918\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(286.44, 25.8857142857143, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(301.32, 25.8857142857143, 'X[1] <= 0.215\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(293.88, 15.531428571428563, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(308.76, 15.531428571428563, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(271.56, 77.65714285714284, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(238.08, 108.72, 'entropy = 0.0\\nsamples = 13\\nvalue = [13, 0]'),\n",
       " Text(200.88000000000002, 170.84571428571428, 'entropy = 0.0\\nsamples = 19\\nvalue = [19, 0]'),\n",
       " Text(245.52, 181.2, 'X[0] <= -0.82\\nentropy = 0.996\\nsamples = 13\\nvalue = [7, 6]'),\n",
       " Text(238.08, 170.84571428571428, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(252.96, 170.84571428571428, 'X[1] <= 0.548\\nentropy = 0.881\\nsamples = 10\\nvalue = [7, 3]'),\n",
       " Text(245.52, 160.49142857142857, 'X[0] <= 0.652\\nentropy = 0.971\\nsamples = 5\\nvalue = [2, 3]'),\n",
       " Text(238.08, 150.13714285714286, 'X[0] <= -0.272\\nentropy = 0.918\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(230.64000000000001, 139.78285714285715, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(245.52, 139.78285714285715, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(252.96, 150.13714285714286, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(260.40000000000003, 160.49142857142857, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(282.72, 201.90857142857143, 'X[0] <= -1.275\\nentropy = 0.614\\nsamples = 66\\nvalue = [10, 56]'),\n",
       " Text(275.28000000000003, 191.5542857142857, 'entropy = 0.0\\nsamples = 12\\nvalue = [0, 12]'),\n",
       " Text(290.16, 191.5542857142857, 'X[0] <= -0.655\\nentropy = 0.691\\nsamples = 54\\nvalue = [10, 44]'),\n",
       " Text(275.28000000000003, 181.2, 'X[1] <= 0.998\\nentropy = 0.722\\nsamples = 5\\nvalue = [4, 1]'),\n",
       " Text(267.84000000000003, 170.84571428571428, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(282.72, 170.84571428571428, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(305.04, 181.2, 'X[1] <= 1.853\\nentropy = 0.536\\nsamples = 49\\nvalue = [6, 43]'),\n",
       " Text(297.6, 170.84571428571428, 'X[0] <= 1.122\\nentropy = 0.709\\nsamples = 31\\nvalue = [6, 25]'),\n",
       " Text(275.28000000000003, 160.49142857142857, 'X[0] <= -0.122\\nentropy = 0.469\\nsamples = 20\\nvalue = [2, 18]'),\n",
       " Text(267.84000000000003, 150.13714285714286, 'X[0] <= -0.36\\nentropy = 0.764\\nsamples = 9\\nvalue = [2, 7]'),\n",
       " Text(260.40000000000003, 139.78285714285715, 'entropy = 0.0\\nsamples = 5\\nvalue = [0, 5]'),\n",
       " Text(275.28000000000003, 139.78285714285715, 'X[0] <= -0.348\\nentropy = 1.0\\nsamples = 4\\nvalue = [2, 2]'),\n",
       " Text(267.84000000000003, 129.42857142857144, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(282.72, 129.42857142857144, 'X[1] <= 1.723\\nentropy = 0.918\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(275.28000000000003, 119.07428571428571, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(290.16, 119.07428571428571, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(282.72, 150.13714285714286, 'entropy = 0.0\\nsamples = 11\\nvalue = [0, 11]'),\n",
       " Text(319.92, 160.49142857142857, 'X[0] <= 1.457\\nentropy = 0.946\\nsamples = 11\\nvalue = [4, 7]'),\n",
       " Text(312.48, 150.13714285714286, 'X[0] <= 1.26\\nentropy = 0.722\\nsamples = 5\\nvalue = [4, 1]'),\n",
       " Text(305.04, 139.78285714285715, 'X[0] <= 1.192\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(297.6, 129.42857142857144, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(312.48, 129.42857142857144, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(319.92, 139.78285714285715, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(327.36, 150.13714285714286, 'entropy = 0.0\\nsamples = 6\\nvalue = [0, 6]'),\n",
       " Text(312.48, 170.84571428571428, 'entropy = 0.0\\nsamples = 18\\nvalue = [0, 18]')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "tree.plot_tree(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- feature_1 <= 0.61\n",
      "|   |--- feature_1 <= -0.81\n",
      "|   |   |--- feature_1 <= -1.45\n",
      "|   |   |   |--- class: 0\n",
      "|   |   |--- feature_1 >  -1.45\n",
      "|   |   |   |--- feature_0 <= -0.29\n",
      "|   |   |   |   |--- feature_0 <= -1.25\n",
      "|   |   |   |   |   |--- feature_1 <= -1.21\n",
      "|   |   |   |   |   |   |--- feature_0 <= -1.33\n",
      "|   |   |   |   |   |   |   |--- feature_0 <= -1.38\n",
      "|   |   |   |   |   |   |   |   |--- feature_0 <= -1.46\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_0 >  -1.46\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_0 >  -1.38\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_0 >  -1.33\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_1 >  -1.21\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- feature_0 >  -1.25\n",
      "|   |   |   |   |   |--- feature_1 <= -0.90\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_1 >  -0.90\n",
      "|   |   |   |   |   |   |--- feature_0 <= -0.91\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_0 >  -0.91\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- feature_0 >  -0.29\n",
      "|   |   |   |   |--- feature_1 <= -1.37\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- feature_1 >  -1.37\n",
      "|   |   |   |   |   |--- feature_1 <= -1.32\n",
      "|   |   |   |   |   |   |--- feature_0 <= -0.05\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_0 >  -0.05\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_1 >  -1.32\n",
      "|   |   |   |   |   |   |--- feature_0 <= -0.22\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_0 >  -0.22\n",
      "|   |   |   |   |   |   |   |--- feature_1 <= -0.86\n",
      "|   |   |   |   |   |   |   |   |--- feature_0 <= 1.59\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_1 <= -0.90\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_1 <= -1.18\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 4\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_1 >  -1.18\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_1 >  -0.90\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_0 >  1.59\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_1 <= -0.97\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_1 >  -0.97\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_1 >  -0.86\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |--- feature_1 >  -0.81\n",
      "|   |   |--- feature_1 <= 0.49\n",
      "|   |   |   |--- feature_0 <= 1.23\n",
      "|   |   |   |   |--- feature_0 <= -1.65\n",
      "|   |   |   |   |   |--- feature_0 <= -1.66\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_0 >  -1.66\n",
      "|   |   |   |   |   |   |--- feature_0 <= -1.66\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_0 >  -1.66\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- feature_0 >  -1.65\n",
      "|   |   |   |   |   |--- feature_0 <= -1.38\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_0 >  -1.38\n",
      "|   |   |   |   |   |   |--- feature_0 <= -1.37\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_0 >  -1.37\n",
      "|   |   |   |   |   |   |   |--- feature_0 <= -1.14\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_0 >  -1.14\n",
      "|   |   |   |   |   |   |   |   |--- feature_0 <= -1.13\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_0 >  -1.13\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_1 <= 0.29\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_1 <= 0.08\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 10\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_1 >  0.08\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 9\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_1 >  0.29\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- feature_0 >  1.23\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |   |--- feature_1 >  0.49\n",
      "|   |   |   |--- feature_0 <= -0.82\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |   |--- feature_0 >  -0.82\n",
      "|   |   |   |   |--- feature_1 <= 0.55\n",
      "|   |   |   |   |   |--- feature_0 <= 0.65\n",
      "|   |   |   |   |   |   |--- feature_0 <= -0.27\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_0 >  -0.27\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_0 >  0.65\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- feature_1 >  0.55\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|--- feature_1 >  0.61\n",
      "|   |--- feature_0 <= -1.27\n",
      "|   |   |--- class: 1\n",
      "|   |--- feature_0 >  -1.27\n",
      "|   |   |--- feature_0 <= -0.65\n",
      "|   |   |   |--- feature_1 <= 1.00\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |   |--- feature_1 >  1.00\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |   |--- feature_0 >  -0.65\n",
      "|   |   |   |--- feature_1 <= 1.85\n",
      "|   |   |   |   |--- feature_0 <= 1.12\n",
      "|   |   |   |   |   |--- feature_0 <= -0.12\n",
      "|   |   |   |   |   |   |--- feature_0 <= -0.36\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_0 >  -0.36\n",
      "|   |   |   |   |   |   |   |--- feature_0 <= -0.35\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_0 >  -0.35\n",
      "|   |   |   |   |   |   |   |   |--- feature_1 <= 1.72\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_1 >  1.72\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_0 >  -0.12\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- feature_0 >  1.12\n",
      "|   |   |   |   |   |--- feature_0 <= 1.46\n",
      "|   |   |   |   |   |   |--- feature_0 <= 1.26\n",
      "|   |   |   |   |   |   |   |--- feature_0 <= 1.19\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_0 >  1.19\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_0 >  1.26\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_0 >  1.46\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- feature_1 >  1.85\n",
      "|   |   |   |   |--- class: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_representation = tree.export_text(classifier)\n",
    "print(text_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
